FROM ollama/ollama:latest

# Start Ollama server in background and pull model during build
RUN nohup bash -c "ollama serve &" && \
    sleep 5 && \
    for i in {1..30}; do \
        if curl -s http://localhost:11434/api/tags >/dev/null 2>&1; then \
            echo "Ollama server is ready"; \
            break; \
        fi; \
        echo "Waiting for Ollama server... ($i/30)"; \
        sleep 2; \
    done && \
    ollama pull phi3:mini && \
    echo "Model downloaded successfully" && \
    pkill ollama && \
    sleep 2